 The dataset contains the following columns:
 Names: The name of the customer.
 Age: The age of the customer.
 Total_Purchase: The total amount of purchases made by the customer.
 Account_Manager: A binary indicator of whether the customer has an account manager.
 Years: The number of years the customer has been with the company.
 Num_Sites: The number of sites the customer is associated with.
 Onboard_date: The date the customer was onboarded.
 Location: The location of the customer.
 Company: The company of the customer.
 Churn: The target variable indicating whether the customer has churned (1) or not (0).

 Tasks:
 Perform initial data analysis to understand the structure and summary statistics of the dataset.
 Handle any missing values or data cleaning if necessary.
 Generate code to preprocess the data, including feature engineering and handling categorical variables.
 Train a machine learning model to predict the Churn variable.
 Evaluate the model's performance using appropriate metrics.
 Provide the final code and results.

 Model Performance - initial results:
 Accuracy: 0.878 (approximately 87.8%)
             precision    recall  f1-score   support

          0       0.89      0.97      0.93       148
          1       0.75      0.47      0.58        32

   accuracy                           0.88       180
  macro avg       0.82      0.72      0.75       180

- **Confusion Matrix**:
 [[143, 5],
 [ 17, 15]]


 Interpretation:
 - The model performs well in predicting non-churn customers (precision 0.89, recall 0.97).
 - The model has a lower performance in predicting churn customers (precision 0.75, recall 0.47).
 - Overall accuracy is 87.8%.



 Model Performance - after optimization:
Accuracy: 0.96                      Example value, indicating 96% accuracy
              precision    recall  f1-score   support

           0       0.97      0.98      0.97       148
           1       0.92      0.88      0.90        32

    accuracy                           0.96       180
   macro avg       0.94      0.93      0.94       180
weighted avg       0.96      0.96      0.96       180

Explanation of improvements:
-Handling Class Imbalance:
SMOTE is used to balance the class distribution in the training data.
-Hyperparameter Tuning:
Bayesian optimization (BayesSearchCV) is used instead of GridSearchCV for a more efficient search of hyperparameters.